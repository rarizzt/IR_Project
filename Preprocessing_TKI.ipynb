{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17Sy49SJCTv7genGNAgL7roVqOiOKIF56",
      "authorship_tag": "ABX9TyPfnDifRkhcbpawSUqSiY76",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rarizzt/IR_Project/blob/main/Preprocessing_TKI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/TKI/dataset_ir_250_sampel.csv')"
      ],
      "metadata": {
        "id": "Wqc3bo76oOjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDA4ocHzli6y",
        "outputId": "00be8787-e0ef-4add-b9e2-4afe7ca822b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m204.8/209.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SEL 2: CLEANING DASAR ---\n",
        "import re\n",
        "import string\n",
        "\n",
        "df['title'] = df['title'].fillna('')\n",
        "df['content_snippet'] = df['content_snippet'].fillna('')\n",
        "\n",
        "df['text_combined'] = df['title'] + \" \" + df['content_snippet']\n",
        "\n",
        "def basic_cleaning(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "print(\"Sedang membersihkan simbol dan angka...\")\n",
        "df['clean_text'] = df['text_combined'].apply(basic_cleaning)\n",
        "\n",
        "print(\"Contoh hasil cleaning:\")\n",
        "print(df['clean_text'].head(1).values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvAlhV2omJXg",
        "outputId": "37a87974-6299-45a1-8e80-5bd69e09bd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sedang membersihkan simbol dan angka...\n",
            "Contoh hasil cleaning:\n",
            "['qatar airways rute balidoha batal terbang malam ini imbas iranisrael qatar airways membatalkan penerbangan internasional rute denpasardoha yang direncanakan terbang malam ini pukul wita dari bandara internasional i gusti ngurah rai bali']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SEL 3: STOPWORD REMOVAL ---\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "factory_stop = StopWordRemoverFactory()\n",
        "stopword_remover = factory_stop.create_stop_word_remover()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return stopword_remover.remove(text)\n",
        "\n",
        "print(\"Sedang menghapus kata sambung (stopword)...\")\n",
        "df['clean_text'] = df['clean_text'].apply(remove_stopwords)\n",
        "\n",
        "print(\"Selesai! Kata sambung hilang.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwYHxyokmWFM",
        "outputId": "0b5d6a36-29e8-4347-f10b-531be840aa31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sedang menghapus kata sambung (stopword)...\n",
            "Selesai! Kata sambung hilang.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SEL 4: STEMMING ---\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from tqdm import tqdm\n",
        "\n",
        "factory_stem = StemmerFactory()\n",
        "stemmer = factory_stem.create_stemmer()\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "print(\"Mulai Stemming (Merubah kata berimbuhan ke kata dasar)...\")\n",
        "print(\"Mohon tunggu, proses ini memakan waktu...\")\n",
        "\n",
        "df['clean_text'] = df['clean_text'].progress_apply(lambda x: stemmer.stem(x))\n",
        "\n",
        "print(\"\\nStemming Selesai!\")\n",
        "print(\"Contoh: 'memakan' ->\", stemmer.stem(\"memakan\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U4oDO4JmZWG",
        "outputId": "1a44840d-d6eb-48ea-bf30-cdedf6f962db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mulai Stemming (Merubah kata berimbuhan ke kata dasar)...\n",
            "Mohon tunggu, proses ini memakan waktu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [01:47<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming Selesai!\n",
            "Contoh: 'memakan' -> makan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SEL 5: TOKENIZATION & SAVE ---\n",
        "import ast\n",
        "df['tokens'] = df['clean_text'].apply(lambda x: x.split())\n",
        "\n",
        "output_path = '/content/drive/MyDrive/TKI/dataset_ir_250_preprocessed_lengkap.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"=\"*40)\n",
        "print(\"PREPROCESSING SELESAI!\")\n",
        "print(f\"File tersimpan di: {output_path}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "print(df[['title', 'clean_text', 'tokens']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVu9z7zPm2o3",
        "outputId": "62495363-3898-48a3-a316-dffc2efb4959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "PREPROCESSING SELESAI!\n",
            "File tersimpan di: /content/drive/MyDrive/TKI/dataset_ir_250_preprocessed_lengkap.csv\n",
            "========================================\n",
            "                                               title  \\\n",
            "0  Qatar Airways Rute Bali-Doha Batal Terbang Mal...   \n",
            "1  Alfamart di IIHF 2025, Dukung Visi Halal Globa...   \n",
            "2  Bahlil Akui Cuan Hilirisasi Baru Dinikmati Inv...   \n",
            "3  Rosan Klaim Perang Iran Vs Israel Belum Berdam...   \n",
            "4              KKP: Pulau Kecil Tak Boleh Ditambang!   \n",
            "\n",
            "                                          clean_text  \\\n",
            "0  qatar airways rute balidoha batal terbang mala...   \n",
            "1  alfamart iihf dukung visi halal global bpjph a...   \n",
            "2  bahlil aku cuan hilir baru nikmat investor per...   \n",
            "3  ros klaim perang iran vs israel dampak investa...   \n",
            "4  kkp pulau kecil tak tambang menteri laut ikan ...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [qatar, airways, rute, balidoha, batal, terban...  \n",
            "1  [alfamart, iihf, dukung, visi, halal, global, ...  \n",
            "2  [bahlil, aku, cuan, hilir, baru, nikmat, inves...  \n",
            "3  [ros, klaim, perang, iran, vs, israel, dampak,...  \n",
            "4  [kkp, pulau, kecil, tak, tambang, menteri, lau...  \n"
          ]
        }
      ]
    }
  ]
}